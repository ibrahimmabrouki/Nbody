{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ibrahimmabrouki/Nbody/blob/main/NbodyAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run this first to get the codes and setup the enviroment"
      ],
      "metadata": {
        "id": "R3apYEbTsq8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
        "!apt update\n",
        "!apt install ./nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
        "!apt --fix-broken install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiLY3LbhwuVk",
        "outputId": "b8af29c4-ff7f-4dc2-bb85-88f6e768aaec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-19 14:54:51--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.39.144\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.39.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 317705436 (303M) [application/x-deb]\n",
            "Saving to: ‘nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb’\n",
            "\n",
            "nsight-systems-2023 100%[===================>] 302.99M   233MB/s    in 1.3s    \n",
            "\n",
            "2024-11-19 14:54:52 (233 MB/s) - ‘nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb’ saved [317705436/317705436]\n",
            "\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "59 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'nsight-systems-2023.2.3' instead of './nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb'\n",
            "nsight-systems-2023.2.3 is already the newest version (2023.2.3.1001-32894139v0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 59 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hamdanabdellatef/Nbody.git\n",
        "%cd Nbody"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWGdNE50sqMD",
        "outputId": "7a59f1ca-9988-45c8-acea-ddba34f00d7f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Nbody'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 11 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (11/11), 15.08 KiB | 15.08 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "/content/Nbody/Nbody/Nbody/Nbody/Nbody\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Here is an example\n",
        "\n",
        "How to compile and run cuda c in colab, and profile it with nsys"
      ],
      "metadata": {
        "id": "UYW2yGN5vAL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -std=c++11 -o vectoradd 01-vector-add.cu -run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LppB9tluysl",
        "outputId": "195eda97-d8e3-4c94-ad20-a58d19bb5a67"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All values calculated correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here How to use nsys with colab"
      ],
      "metadata": {
        "id": "bU_yn_fIyGeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys profile --stats=true -o vector-add-report ./vectoradd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwkp5cnqyGFB",
        "outputId": "9d34f716-7d44-45f6-e8d5-1f08b80941c2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executable not found in current directory or standard search paths\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp87YxwqsWFD"
      },
      "source": [
        "---\n",
        "# Final Exercise: Accelerate and Optimize an N-Body Simulator\n",
        "\n",
        "An [n-body](https://en.wikipedia.org/wiki/N-body_problem) simulator predicts the individual motions of a group of objects interacting with each other gravitationally. 01-nbody.cu contains a simple, though working, n-body simulator for bodies moving through 3 dimensional space.\n",
        "\n",
        "In its current CPU-only form, this application takes about 5 seconds to run on 4096 particles, and **20 minutes** to run on 65536 particles. Your task is to GPU accelerate the program, retaining the correctness of the simulation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPYT41S2sWFD"
      },
      "source": [
        "### Considerations to Guide Your Work\n",
        "\n",
        "Here are some things to consider before beginning your work:\n",
        "\n",
        "- Especially for your first refactors, the logic of the application, the `bodyForce` function in particular, can and should remain largely unchanged: focus on accelerating it as easily as possible.\n",
        "- The code base contains a for-loop inside `main` for integrating the interbody forces calculated by `bodyForce` into the positions of the bodies in the system. This integration both needs to occur after `bodyForce` runs, and, needs to complete before the next call to `bodyForce`. Keep this in mind when choosing how and where to parallelize.\n",
        "- Use a **profile driven** and iterative approach.\n",
        "- You are not required to add error handling to your code, but you might find it helpful, as you are responsible for your code working correctly.\n",
        "\n",
        "**Have Fun!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWmLxkzcsWFE"
      },
      "source": [
        "Use this cell to compile the nbody simulator. Although it is initially a CPU-only application, is does accurately simulate the positions of the particles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "scrolled": true,
        "id": "tcnd47mesWFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58af92a-691c-4a4a-8edf-5fb91d2e4e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Nbody'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 17 (delta 5), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (17/17), 18.68 KiB | 9.34 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "/content/Nbody/Nbody/Nbody/Nbody/Nbody/Nbody\n",
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[K01-optimizednbody.cu: No such file or directory\n",
            "compilation terminated.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ibrahimmabrouki/Nbody.git\n",
        "%cd Nbody\n",
        "\n",
        "!nvcc -std=c++11 -o optimizednbody 01-optimizednbody.cu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFvPmcuasWFF"
      },
      "source": [
        "It is highly recommended you use the profiler to assist your work. Execute the following cell to generate a report file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcf2tIU-sWFF",
        "outputId": "11cf48d7-b419-4057-b2f8-85c4e260eb89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executable not found in current directory or standard search paths\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true --force-overwrite=true -o optimizednbody-report ./optimizednbody"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYpBRvH2sWFF"
      },
      "source": [
        "Here we import a function that will run your `nbody` simulator against a various number of particles, checking for performance and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZikBm-RgsWFG"
      },
      "outputs": [],
      "source": [
        "from assessment import run_assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sAIrVNNsWFG"
      },
      "source": [
        "Execute the following cell to run and assess `nbody`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "80Q9QOq4sWFH"
      },
      "outputs": [],
      "source": [
        "run_assessment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30o3xXsxsWFH"
      },
      "source": [
        "## Generate a Certificate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-PEBplRsWFH"
      },
      "source": [
        "If you passed the assessment, please return to the course page (shown below) and click the \"ASSESS TASK\" button, which will generate your certificate for the course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptfEL1X6sWFI"
      },
      "source": [
        "![run_assessment](https://github.com/hamdanabdellatef/Nbody/blob/main/images/run_assessment.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpaUlWrYsWFI"
      },
      "source": [
        "## Advanced Content\n",
        "\n",
        "The following sections, for those of you with time and interest, introduce more intermediate techniques involving some manual device memory management, and using non-default streams to overlap kernel execution and memory copies.\n",
        "\n",
        "After learning about each of the techniques below, try to further optimize your nbody simulation using these techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NviPG3N3sWFI"
      },
      "source": [
        "---\n",
        "## Manual Device Memory Allocation and Copying\n",
        "\n",
        "While `cudaMallocManaged` and `cudaMemPrefetchAsync` are performant, and greatly simplify memory migration, sometimes it can be worth it to use more manual methods for memory allocation. This is particularly true when it is known that data will only be accessed on the device or host, and the cost of migrating data can be reclaimed in exchange for the fact that no automatic on-demand migration is needed.\n",
        "\n",
        "Additionally, using manual device memory management can allow for the use of non-default streams for overlapping data transfers with computational work. In this section you will learn some basic manual device memory allocation and copy techniques, before extending these techniques to overlap data copies with computational work.\n",
        "\n",
        "Here are some CUDA commands for manual device memory management:\n",
        "\n",
        "- `cudaMalloc` will allocate memory directly to the active GPU. This prevents all GPU page faults. In exchange, the pointer it returns is not available for access by host code.\n",
        "- `cudaMallocHost` will allocate memory directly to the CPU. It also \"pins\" the memory, or page locks it, which will allow for asynchronous copying of the memory to and from a GPU. Too much pinned memory can interfere with CPU performance, so use it only with intention. Pinned memory should be freed with `cudaFreeHost`.\n",
        "- `cudaMemcpy` can copy (not transfer) memory, either from host to device or from device to host."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcONWcHzsWFJ"
      },
      "source": [
        "### Manual Device Memory Management Example\n",
        "\n",
        "Here is a snippet of code that demonstrates the use of the above CUDA API calls.\n",
        "\n",
        "```cpp\n",
        "int *host_a, *device_a;        // Define host-specific and device-specific arrays.\n",
        "cudaMalloc(&device_a, size);   // `device_a` is immediately available on the GPU.\n",
        "cudaMallocHost(&host_a, size); // `host_a` is immediately available on CPU, and is page-locked, or pinned.\n",
        "\n",
        "initializeOnHost(host_a, N);   // No CPU page faulting since memory is already allocated on the host.\n",
        "\n",
        "// `cudaMemcpy` takes the destination, source, size, and a CUDA-provided variable for the direction of the copy.\n",
        "cudaMemcpy(device_a, host_a, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "kernel<<<blocks, threads, 0, someStream>>>(device_a, N);\n",
        "\n",
        "// `cudaMemcpy` can also copy data from device to host.\n",
        "cudaMemcpy(host_a, device_a, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "verifyOnHost(host_a, N);\n",
        "\n",
        "cudaFree(device_a);\n",
        "cudaFreeHost(host_a);          // Free pinned memory like this.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPy7iYuDsWFJ"
      },
      "source": [
        "### Exercise: Manually Allocate Host and Device Memory\n",
        "\n",
        "The most recent iteration of the vector addition application, [01-stream-init-solution](../edit/06-stream-init/solutions/01-stream-init-solution.cu), is using `cudaMallocManaged` to allocate managed memory first used on the device by the initialization kernels, then on the device by the vector add kernel, and then by the host, where the memory is automatically transferred, for verification. This is a sensible approach, but it is worth experimenting with some manual device memory allocation and copying to observe its impact on the application's performance.\n",
        "\n",
        "Refactor the [01-stream-init-solution](../edit/06-stream-init/solutions/01-stream-init-solution.cu) application to **not** use `cudaMallocManaged`. In order to do this you will need to do the following:\n",
        "\n",
        "- Replace calls to `cudaMallocManaged` with `cudaMalloc`.\n",
        "- Create an additional vector that will be used for verification on the host. This is required since the memory allocated with `cudaMalloc` is not available to the host. Allocate this host vector with `cudaMallocHost`.\n",
        "- After the `addVectorsInto` kernel completes, use `cudaMemcpy` to copy the vector with the addition results, into the host vector you created with `cudaMallocHost`.\n",
        "- Use `cudaFreeHost` to free the memory allocated with `cudaMallocHost`.\n",
        "\n",
        "Refer to [the solution](../edit/07-manual-malloc/solutions/01-manual-malloc-solution.cu) if you get stuck."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPwSept2sWFK"
      },
      "outputs": [],
      "source": [
        "!nvcc -o vector-add-manual-alloc 06-stream-init/solutions/01-stream-init-solution.cu -run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvSWymuUsWFL"
      },
      "source": [
        "After completing the refactor, open a report in Nsight Systems, and use the timeline to do the following:\n",
        "\n",
        "- Notice that there is no longer a *Unified Memory* section of the timeline.\n",
        "- Comparing this timeline to that of the previous refactor, compare the run times of `cudaMalloc` in the current application vs. `cudaMallocManaged` in the previous.\n",
        "- Notice how in the current application, work on the initialization kernels does not start until a later time than it did in the previous iteration. Examination of the timeline will show the difference is the time taken by `cudaMallocHost`. This clearly points out the difference between memory transfers, and memory copies. When copying memory, as you are doing presently, the data will exist in 2 different places in the system. In the current case, the allocation of the 4th host-only vector incurs a small cost in performance, compared to only allocating 3 vectors in the previous iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-V7rJnjsWFM"
      },
      "source": [
        "---\n",
        "## Using Streams to Overlap Data Transfers and Code Execution\n",
        "\n",
        "The following slides present upcoming material visually, at a high level. Click through the slides before moving on to more detailed coverage of their topics in following sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywXpy16-sWFM"
      },
      "outputs": [],
      "source": [
        "%%HTML\n",
        "\n",
        "<div align=\"center\"><iframe src=\"https://view.officeapps.live.com/op/view.aspx?src=https://developer.download.nvidia.com/training/courses/C-AC-01-V1/embedded/task3/NVVP-Streams-3.pptx\" width=\"800px\" height=\"500px\" frameborder=\"0\"></iframe></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S4zsekmsWFN"
      },
      "source": [
        "In addition to `cudaMemcpy` is `cudaMemcpyAsync` which can asynchronously copy memory either from host to device or from device to host as long as the host memory is pinned, which can be done by allocating it with `cudaMallocHost`.\n",
        "\n",
        "Similar to kernel execution, `cudaMemcpyAsync` is only asynchronous by default with respect to the host. It executes, by default, in the default stream and therefore is a blocking operation with regard to other CUDA operations occurring on the GPU. The `cudaMemcpyAsync` function, however, takes as an optional 5th argument, a non-default stream. By passing it a non-default stream, the memory transfer can be concurrent to other CUDA operations occurring in other non-default streams.\n",
        "\n",
        "A common and useful pattern is to use a combination of pinned host memory, asynchronous memory copies in non-default streams, and kernel executions in non-default streams, to overlap memory transfers with kernel execution.\n",
        "\n",
        "In the following example, rather than wait for the entire memory copy to complete before beginning work on the kernel, segments of the required data are copied and worked on, with each copy/work segment running in its own non-default stream. Using this technique, work on parts of the data can begin while memory transfers for later segments occur concurrently. Extra care must be taken when using this technique to calculate segment-specific values for the number of operations, and the offset location inside arrays, as shown here:\n",
        "\n",
        "```cpp\n",
        "int N = 2<<24;\n",
        "int size = N * sizeof(int);\n",
        "\n",
        "int *host_array;\n",
        "int *device_array;\n",
        "\n",
        "cudaMallocHost(&host_array, size);               // Pinned host memory allocation.\n",
        "cudaMalloc(&device_array, size);                 // Allocation directly on the active GPU device.\n",
        "\n",
        "initializeData(host_array, N);                   // Assume this application needs to initialize on the host.\n",
        "\n",
        "const int numberOfSegments = 4;                  // This example demonstrates slicing the work into 4 segments.\n",
        "int segmentN = N / numberOfSegments;             // A value for a segment's worth of `N` is needed.\n",
        "size_t segmentSize = size / numberOfSegments;    // A value for a segment's worth of `size` is needed.\n",
        "\n",
        "// For each of the 4 segments...\n",
        "for (int i = 0; i < numberOfSegments; ++i)\n",
        "{\n",
        "  // Calculate the index where this particular segment should operate within the larger arrays.\n",
        "  segmentOffset = i * segmentN;\n",
        "\n",
        "  // Create a stream for this segment's worth of copy and work.\n",
        "  cudaStream_t stream;\n",
        "  cudaStreamCreate(&stream);\n",
        "  \n",
        "  // Asynchronously copy segment's worth of pinned host memory to device over non-default stream.\n",
        "  cudaMemcpyAsync(&device_array[segmentOffset],  // Take care to access correct location in array.\n",
        "                  &host_array[segmentOffset],    // Take care to access correct location in array.\n",
        "                  segmentSize,                   // Only copy a segment's worth of memory.\n",
        "                  cudaMemcpyHostToDevice,\n",
        "                  stream);                       // Provide optional argument for non-default stream.\n",
        "                  \n",
        "  // Execute segment's worth of work over same non-default stream as memory copy.\n",
        "  kernel<<<number_of_blocks, threads_per_block, 0, stream>>>(&device_array[segmentOffset], segmentN);\n",
        "  \n",
        "  // `cudaStreamDestroy` will return immediately (is non-blocking), but will not actually destroy stream until\n",
        "  // all stream operations are complete.\n",
        "  cudaStreamDestroy(stream);\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y0-NTMdsWFN"
      },
      "source": [
        "### Exercise: Overlap Kernel Execution and Memory Copy Back to Host\n",
        "\n",
        "The most recent iteration of the vector addition application, [01-manual-malloc-solution.cu](../edit/07-manual-malloc/solutions/01-manual-malloc-solution.cu), is currently performing all of its vector addition work on the GPU before copying the memory back to the host for verification.\n",
        "\n",
        "Refactor [01-manual-malloc-solution.cu](../edit/07-manual-malloc/solutions/01-manual-malloc-solution.cu) to perform the vector addition in 4 segments, in non-default streams, so that asynchronous memory copies can begin before waiting for all vector addition work to complete. Refer to [the solution](../edit/08-overlap-xfer/solutions/01-overlap-xfer-solution.cu) if you get stuck."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ayga3WksWFO"
      },
      "outputs": [],
      "source": [
        "!nvcc -o vector-add-manual-alloc 07-manual-malloc/solutions/01-manual-malloc-solution.cu -run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvwXfylMsWFP"
      },
      "source": [
        "After completing the refactor, open a report in Nsight Systems, and use the timeline to do the following:\n",
        "\n",
        "- Note when the device to host memory transfers begin, is it before or after all kernel work has completed?\n",
        "- Notice that the 4 memory copy segments themselves do not overlap. Even in separate non-default streams, only one memory transfer in a given direction (DtoH here) at a time can occur simultaneously. The performance gains here are in the ability to start the transfers earlier than otherwise, and it is not hard to imagine in an application where a less trivial amount of work was being done compared to a simple addition operation, that the memory copies would not only start earlier, but also overlap with kernel execution."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "R3apYEbTsq8Y",
        "UYW2yGN5vAL1"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}